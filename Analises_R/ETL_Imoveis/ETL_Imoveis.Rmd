---
title: "Análise venda de imóveis"
author: "Jairo Lopes"
output: rmdformats::readthedown
css: "style.css"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
library(tidyverse)
library(GGally)
library(RColorBrewer)
library(plotly)
library(QuantPsyc)
library(car)
options(scipen = 999)

df <- read_csv("House.csv")
colnames(df) <- c('media de lucro de venda', 'media idade das casas', 'media numero de salas','media numero de quartos', 'populacao da regiao', 'valor da casa', 'endereco')
```

# Resumo
Este projeto fará uma breve análise exploratória dos dados de um dataset de venda de casas, para realizar a predição de preços de novas casas com caracteristicas semelhantes as ja vendidas



# Visão geral do dataset
Verificando quantidade de registros e de colunas respectivamente do conjunto de dados

```{r}
df %>% str %>% knitr::kable()
```


```{r}
df %>% head(4) %>% knitr::kable()
```


___



# Visualizando a distribuição de preços das casas por quantidade de quartos


```{r}
plot_ly(data = df, x=~`media numero de quartos`, y=~`valor da casa`, type = "scatter") %>%
layout(xaxis=list(title="Numero de quartos"), yaxis=list(title="Valor da casa"))
```



**OBS:** Não há grande variação de preço por numero de quartos, mas da pra perceber que casas que contém em media 2 quartos, são um pouco mais baratas em seu **valor máximo**


___



# Visualizando a distribuição de preços das casas por quantidade de salas

```{r}
plot_ly(data = df, x=~`media numero de salas`, y=~`valor da casa`, type = "scatter", marker=list(color="seagreen"))
```



**OBS:** obviamente, quanto maior a quantidade de salas, maior o preço da casa, em alguns poucos casos, casas com numero menor de salas sao mais caras

**OBS 2:** Também é possivel notar que a grande maioria das casas possuem entre 6 a 8 salas


___



# Visualizando a distribuição de salas por quantidade de quartos


```{r}
plot_ly(data=df, x=~`media numero de quartos`, y=~`media numero de salas`, type="scatter", marker=list(color="darkmagenta"))
```




**OBS:** Podemos ver que todas as casas com 5 quartos ou mais, possuem no mínimo 7 salas

**OBS 2:** Também observamos que casas com 2 quartos, possuem no maximo 7 salas


___



# Visualizando distribuição do preço da casa baseado pela idade da mesma


```{r}
plot_ly(data=df, x=~`media idade das casas`, y=~`valor da casa`, type="scatter", marker=list(color="darkcyan"))
```




**OBS:** E mais uma amostra linear onde indica que, quanto mais velha a casa, maior o seu valor


___


# Visualizando distribuição de preços da casa por tamanho da população da região

```{r}
plot_ly(data=df, x=~`populacao da regiao`, y=~`valor da casa`, type="scatter", marker=list(color="firebrick"))
```



**OBS:** Quanto maior a população da região, maior o valor do imóvel



___



# Visualizando correlações entre as variáveis


```{r}
ggcorr(df, label = T, hjust = 0.85)
```

**OBS:** As maiores correlações com a variavel "valor da casa" sao: **populacao da regiao, idade da casa, lucro de venda e numero de salas** 


___

# Machine Learning

## Escolha de variáveis

### Filtrando variáveis significantes para o modelo
Três modelos serão criados, o **modelo1** com as variaveis `lucro de venda` e `idade das casas`.

O **modelo2** com as variaveis `lucro de venda`, `idade das casas` e `populacao da regiao`.

O **modelo3** com as variaveis `lucro de venda`, `idade das casas`, `populacao da regiao` e `numero de salas`.


```{r}
modelo1 <- lm(`valor da casa` ~ -1 + `media de lucro de venda` + `media idade das casas`, data = df)
modelo2 <- lm(`valor da casa` ~ -1 + `media de lucro de venda` + `media idade das casas` + `populacao da regiao`, data = df)
modelo3 <- lm(`valor da casa` ~ -1 + `media de lucro de venda` + `media idade das casas` + `populacao da regiao` + `media numero de salas`, data = df)

```

# Avaliando desempenho de cada modelo {.tabset}
## Modelo1
```{r}
modelo1 %>% summary
```

**OBS 1: **Quase **96%** dos dados do valor da casa, podem ser explicados pelas variáveis preditoras escolhidas

**OBS 2: **Também e perceptivel que a margem de erros das duas variáveis são proximas a zero

___

## Modelo2
```{r}
modelo2 %>% summary
```

**OBS 1: ** **96,43%** dos dados do valor da casa, podem ser explicados pelas variáveis preditoras escolhidas

**OBS 2: **Também e perceptivel que a margem de erros das **três** variáveis são proximas a zero

___

## Modelo3
```{r}
modelo3 %>% summary
```

**OBS 1: ** Não há diferença se comparado ao modelo dois no que diz respeito a explicação dos dados

**OBS 2: **É notavel que a variavel "numero de salas" tem uma margem de erro consideravelmente maior que as outras 3 variaveis

___



___

# Visualizando o desempenho das predições dos 3 modelos {.tabset}
Será comparado os resultados estimados com os resultados originais em um gráfico de dispersão para medir a linearidade das predições com os dados reais..

## Predições do modelo 1

```{r}
pred1 <- tibble(dadosReais=df$`valor da casa`, predicoes=modelo1$fitted.values, residuosPadronizados=rstandard(modelo1))

plot_ly(data=pred1, x=~dadosReais, y=~predicoes, type = "scatter", marker=list(color="brown"))
```



**OBS: **Criado com as variáveis independentes: `media de lucro de venda` e `media idade das casas`

___

## Predições do modelo 2

```{r}
pred2 <- tibble(N=1:5000, dadosReais=df$`valor da casa`, predicoes=modelo2$fitted.values, residuos=modelo2$residuals, residuosPadronizados=rstandard(modelo2))

plot_ly(data=pred2, x=~dadosReais, y=~predicoes, type="scatter", marker=list(color="brown"))
```



**OBS: **Criado com as variáveis independentes: `media de lucro de venda`, `media idade das casas` e `populacao da regiao` 

___

## Predições do modelo 3

```{r}
pred3 <- tibble(dadosReais=df$`valor da casa`, predicoes=modelo3$fitted.values, residuosPadronizados=rstandard(modelo3))

plot_ly(data=pred3, x=~dadosReais, y=~predicoes, type="scatter", marker=list(color="brown"))
```



**OBS: **Criado com as variáveis independentes: `media de lucro de venda`, `media idade das casas`, `populacao da regiao`, `media numero de salas`

___

# Observações sobre as predições
Claramente o modelo2 teve um desempenho melhor, justamente por possuir as duas variáveis de maior correlação com a variável valor da casa

___



# Verificando possiveis outliers do melhor modelo
Foi filtrado todos os residuos padronizados com valor maior ou igual a **1.96**, ou, menor ou igual **-1.96**


```{r}
pred2 %>% filter(residuosPadronizados >= 1.96 | residuosPadronizados <= -1.96) %>% nrow()
```
**OBS:** Dos 5 mil registros, 241 são outliers


## Resumo dos resíduos padronizados

```{r}
rstandard(modelo2) %>% summary
```

___


# Comparando desempenho do modelo2 com e sem outliers
Armazenando a identificação dos outliers identificados dentro de uma variavel vetor, e usando esta variavel para remover os outliers do modelo.

```{r}
outliers <- pred2 %>% filter(residuosPadronizados >= 1.96 | residuosPadronizados <= -1.96) %>% select(N)

outliers <- outliers$N

reaisSemOutliers <- df$`valor da casa`[-outliers]
predSemOutliers <- modelo2$fitted.values[-outliers]
semOutliers <- tibble(dadosReais=reaisSemOutliers, predicoes=predSemOutliers)
```

# Visualizando o desempenho do modelo2 com e sem outliers {.tabset}

## Modelo2 COM outliers

```{r}
plot_ly(data=pred2, x=~dadosReais, y=~predicoes, type="scatter", marker=list(color="#006680"))
```



**OBS:** Extremidades mais dispersas.

___


## Modelo2 SEM outliers

```{r}
plot_ly(data=semOutliers, x=~dadosReais, y=~predicoes, type="scatter", marker=list(color="#006680"))
```

**OBS:** Extremidades mais concentradas

___


# Individuos influentes
Dados influentes sao dados que geram impacto no modelo, que caso sejam retirados, pode haver alterações significativas.

Será feita uma verificação se há outliers influentes, para isso, será utilizada a métrica **Distância de cook**.

## Distância de cook
A distância de cook nada mais é que uma forma de identificar se um certo dado é influente.

Para saber se o valor da distância de cook indica um ponto influente, é necessário que o o valor da distancia de cook seja próximo, igual ou maior que 1.

Ou seja, dados que possuem o valor da distância de cook semalhantes á `1.99`, `1.20`, `0.98`, são prováveis pontos influentes. E valores da distancia de cook semlhantes á `0.03`, `0.09`, `0.4`, são registros que **NÃO** são muio influentes, e que sua retirada nao deve causar muito impacto.

## Visualizando distância de cook dos outliers

```{r}
pred2$distanciaCook <- cooks.distance(modelo2)
outliers <- pred2 %>% filter(residuosPadronizados >= 1.96 | residuosPadronizados <= -1.96)


plot_ly(data = outliers, x=~N, y=~distanciaCook, type = "scatter")
```


**OBS:** Apesar de **NÃO** haver valores que indicam forte influência entre os outliers, há dois indivíduos que são um pouco mais influentes que a maioria, os registros `129` e `963`. Caso tivessem valores mais elevados, não seriam removidos do modelo mesmo sendo outliers.


___

# Tunando o modelo2 {.tabset}
Reaplicando o modelo2 sem outliers baseado nas análises realizadas, e fazendo uma comparação com o antigo modelo2 original

```{r}
outs <- pred2 %>% filter(residuosPadronizados >= 1.96 | residuosPadronizados <= -1.96) %>% select(N)
outs <- outs$N


modelo2SemOut <- lm(`valor da casa` ~ -1 + `media de lucro de venda` + `media idade das casas` + `populacao da regiao`, data = df[-outs,])
```



## Métricas do modelo SEM outliers

```{r}
modelo2SemOut %>% summary
```

**OBS: **De acordo com a métrica **Multiple R-squared**, `97.25%` dos dados do valor da casa, podem ser explicados pelas variáveis preditoras escolhidas **SEM** outliers


## Métricas do modelo COM outliers

```{r}
modelo2 %>% summary
```

**OBS: **De acordo com a métrica **Multiple R-squared**, `96.43%` dos dados do valor da casa, podem ser explicados pelas variáveis preditoras escolhidas **COM** outliers

___

